---
title: "SVR Round 3"
author: "Tay Le Rui"
date: "2025-11-07"
output: html_document
---

```{r}
library(dplyr)
library(readr)
library(kernlab)
library(tibble)

set.seed(42)
```

```{r}
source("results_function.R")

```

```{r}
# 2) Config: data paths, target, horizon --------------------------------------
train_path <- "../1 Month/train_1m.csv"     # change for 6m / 12m runs
test_path  <- "../1 Month/test_1m.csv"

target <- "y_lr_1m"   # change to your 3M, 6m , 12m return column
h <- 1L               # monthly data: 1, 3, 6, 12; 
```

```{r}
train_df <- read.csv(train_path, check.names = FALSE)
test_df  <- read.csv(test_path,  check.names = FALSE)

stopifnot(target %in% names(train_df))
```


```{r}
# 4) SVR wrappers compatible with your CV hooks --------------------------------

`%||%` <- function(a, b) if (is.null(a)) b else a

# Standardize using train-fold stats
.fit_scaler <- function(x) {
  mu <- colMeans(x)
  sd <- apply(x, 2, sd)
  sd[sd == 0 | is.na(sd)] <- 1
  list(mu = mu, sd = sd)
}
.apply_scaler <- function(x, scaler) {
  x <- as.matrix(x)
  x <- sweep(x, 2, scaler$mu, "-")
  sweep(x, 2, scaler$sd, "/")
}

# Optional PCA on standardized X
.fit_pca <- function(x, k = NULL) {
  if (is.null(k) || k <= 0) return(NULL)
  prcomp(x, center = FALSE, scale. = FALSE, rank. = k)
}
.apply_pca <- function(x, pca) {
  if (is.null(pca)) return(x)
  as.matrix(x) %*% pca$rotation
}
```

```{r}
# ---- Fit function for your CV (kernel = "linear" or "rbf")
fit_fn_svr <- function(x, y, params, standardize = FALSE) {
  stopifnot(is.numeric(y))
  x <- as.data.frame(x)

  # 1) scale
  if (standardize){
  scaler <- .fit_scaler(x)
  x_std  <- .apply_scaler(x, scaler)
  } else{
    scaler <- list(mu = rep(0, ncol(x)), sd = rep(1, ncol(x)))
    x_std  <- as.matrix(x)
  }

  # 2) optional PCA
  pca_k <- params$pca_k %||% 0L
  pca <- .fit_pca(x_std, k = pca_k)
  x_final <- .apply_pca(x_std, pca)

  # 3) kernel + hyperparams
  kernel <- params$kernel %||% "linear"
  if (kernel == "linear") {
    kf <- "vanilladot"; kpar <- list()
  } else if (kernel == "rbf") {
    kf <- "rbfdot"
    sigma <- params$rbf_sigma %||% stop("rbf_sigma required for RBF")
    kpar <- list(sigma = sigma)
  } else {
    stop("Unsupported kernel: ", kernel)
  }
  C <- params$cost %||% 1

  # 4) fit ksvm
  mdl <- kernlab::ksvm(
    x      = as.matrix(x_final),
    y      = y,
    type   = "eps-svr",
    kernel = kf,
    kpar   = kpar,
    C      = C,
    scaled = FALSE
  )

  list(ksvm = mdl, scaler = scaler, pca = pca, kernel = kernel)
}

# ---- Predict function for your CV
predict_fn_svr <- function(model, new_x) {
  new_x <- as.data.frame(new_x)
  new_x_std   <- .apply_scaler(new_x, model$scaler)
  new_x_final <- .apply_pca(new_x_std, model$pca)
  as.numeric(predict(model$ksvm, newdata = as.matrix(new_x_final)))
}
```

```{r}
# 5) Build hyperparameter grids -------------------------------------------------

# Count predictors excluding date + target to size PCA options
infer_pred_count <- function(df) {
  y_col <- names(df)[ncol(df)]
  p <- ncol(dplyr::select(df, -dplyr::any_of(c(y_col, "date"))))
  max(p, 1L)
}
n_pred  <- infer_pred_count(train_df)
max_pcs <- min(150L, n_pred)

grid_lin <- list(
  kernel = c("linear"),
  cost   = c(1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100)
)

grid_rbf <- list(
  kernel    = c("rbf"),
  cost      = c(1e-3, 1e-2, 1e-1, 1, 10, 100),
  rbf_sigma = c(1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1),
  pca_k     = c(0L, min(20L, max_pcs), min(50L, max_pcs)) 
)
```

```{r}
# 6) Run your recursive CV tuner (without purging) --------------------------------

set.seed(42)
res_lin <- ts_cv_hyperparameter_tuning(
  train_data  = train_df,
  fit_fn      = fit_fn_svr,
  predict_fn  = predict_fn_svr,
  param_grid  = grid_lin,
  n_folds     = 5,            # controls initial size in your splitter
  cumulative  = TRUE,
  model_name  = "SVR-linear"
)

set.seed(42)
res_rbf <- ts_cv_hyperparameter_tuning(
  train_data  = train_df,
  fit_fn      = fit_fn_svr,
  predict_fn  = predict_fn_svr,
  param_grid  = grid_rbf,
  n_folds     = 5,
  cumulative  = TRUE,
  model_name  = "SVR-rbf"
)
```

```{r}
# 7) Pick best by mean_cv_mse ---------------------------------------------------
best_lin <- res_lin %>% arrange(mean_cv_mse) %>% slice(1)
best_rbf <- res_rbf %>% arrange(mean_cv_mse) %>% slice(1)

chosen <- "linear"
best_params <- as.list(best_lin)
best_rmse <- sqrt(best_lin$mean_cv_mse)

if (!is.na(best_rbf$mean_cv_mse) && best_rbf$mean_cv_mse < best_lin$mean_cv_mse) {
  chosen <- "rbf"
  best_params <- as.list(best_rbf)
  best_rmse <- sqrt(best_rbf$mean_cv_mse)
}

cat("Chosen model:", chosen, "with CV RMSE ~", round(best_rmse, 6), "\n")
```

```{r}
# ---------------------------
# 8) Rolling forecast on test
# ---------------------------

# remove metric column from params before passing to fit
best_params$mean_cv_mse <- NULL

y_col  <- names(train_df)[ncol(train_df)]
x_cols <- setdiff(names(train_df), c(y_col, "date"))

# choose one:
window_mode  <- "sliding"   # "expanding" or "sliding"
window_size  <- 300L          # used only if window_mode == "sliding"
purge        <- FALSE          # keep TRUE for h-step targets

# start with the full training set you used for CV
train_pool <- train_df

n_test   <- nrow(test_df)
pred_vec <- numeric(n_test)

for (i in seq_len(n_test)) {

  # 1) build the current training fold
  train_fold <- train_pool

  # purge last h rows to prevent leakage into the i-th test point
  if (purge) {
    n_keep <- nrow(train_fold) - h
    if (n_keep <= 0) stop("Not enough rows after purging; increase initial training size or reduce h.")
    train_fold <- train_fold[seq_len(n_keep), , drop = FALSE]
  }

  x_train <- train_fold[, x_cols, drop = FALSE]
  y_train <- train_fold[[y_col]]

  # 2) fit with previously chosen hyperparameters
  mdl <- fit_fn_svr(x = x_train, y = y_train, params = best_params)

  # 3) predict the current test row
  x_new <- test_df[i, x_cols, drop = FALSE]
  pred_vec[i] <- predict_fn_svr(mdl, x_new)

  # 4) advance the window
  # If ground truth exists in test, you can fold it in for expanding/sliding updates.
  if (window_mode == "expanding") {
    if (y_col %in% names(test_df)) {
      train_pool <- dplyr::bind_rows(train_pool, test_df[i, , drop = FALSE])
    } else {
      # no y_true available â†’ keep the same train_pool (pure rolling origin without update)
      train_pool <- train_pool
    }
  } else if (window_mode == "sliding") {
    # keep only the most recent 'window_size' rows (after optionally appending truth)
    if (y_col %in% names(test_df)) {
      tmp <- dplyr::bind_rows(train_pool, test_df[i, , drop = FALSE])
    } else {
      tmp <- train_pool
    }
    if (nrow(tmp) > window_size) {
      train_pool <- tmp[(nrow(tmp) - window_size + 1):nrow(tmp), , drop = FALSE]
    } else {
      train_pool <- tmp
    }
  } else {
    stop("window_mode must be 'expanding' or 'sliding'")
  }
}
```

```{r}
da<-directional_accuracy(pred_vec, test_df[[target]])

result_df <- tibble::tibble(
  accuracy   = da$accuracy,
  precision  = da$precision,
  recall     = da$recall,
  F1         = da$F1,
  TP         = da$counts["TP"],
  TN         = da$counts["TN"],
  FP         = da$counts["FP"],
  FN         = da$counts["FN"]
)


#write_csv(result_df, paste0("../Results/directional_accuracy_summary_",h,"_Month.csv"))
```


```{r}
# 9) Output tables and save -----------------------------------------------------

id_cols <- names(test_df)[tolower(names(test_df)) %in% c("date","id","timestamp")]

out <- dplyr::bind_cols(
  if (length(id_cols)) test_df %>% dplyr::select(dplyr::all_of(id_cols)) else NULL,
  tibble(row_index = seq_len(nrow(test_df))),
  tibble(pred = pred_vec)
)

if (target %in% names(test_df)) {
  out <- dplyr::bind_cols(out, tibble(y_true = test_df[[target]]))
}

pred_path    <- paste0("predictions_svr_h", h, ".csv")
summary_path <- paste0("../Results/svr_timeseries_model_summary_h_Rolling_window_", h, ".csv")

#Level MSE
rolling_results <- tibble(
  date = as.Date(test_df$date),
  predicted = pred_vec,     # your prediction vector
  actual    = test_df[[target]]
)

prices <- read_csv("only_brent.csv")

final_results <- level_price_results(
  rolling_results = rolling_results,
  prices          = prices,
  test_dates      = test_df$date
)


#readr::write_csv(out, pred_path)

summary_tbl <- tibble(
  model_chosen = chosen,
  best_cv_rmse = best_rmse,
  best_mse = best_rmse ^2,
  best_level_mse = MSE(final_results[["pred_level"]],final_results[["actual_level"]]),
  horizon_h    = h,
  folds_info   = "recursive_split_cv"
)



#readr::write_csv(summary_tbl, summary_path)

print(list(
  horizon_h    = h,
  n_train      = nrow(train_df),
  n_test       = nrow(test_df),
  n_predictors = length(x_cols),
  model_chosen = chosen,
  pred_path    = pred_path,
  summary_path = summary_path
))
```


```{r}
summary_tbl
```











